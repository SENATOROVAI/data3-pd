<html><head><title>Data Scientist - Seattle, WA</title></head>
<body><h2>Data Scientist - Seattle, WA</h2>
<ul><li>Ability to present technical results to less technical audience including written narratives</li><li>Bachelor's degree in Statistics, Applied Math, Operations Research, Economics, or a related quantitative field with 5 years of working experience in the Data Science Field</li><li>Proficient with data analysis and modeling software such as Spark, R etc</li><li>Proficient with using scripting language such as Python and data manipulation/analysis libraries such as Scikit-learn and Pandas for analyzing and modeling data</li><li>Experienced in using multiple data science methodologies to solve complex business problems</li><li>Experienced in handling large data sets using SQL and databases in a business environment</li></ul>

A fulfillment center can appear to be a chaotic place. With millions of items moving in and out of an area twice as large as your average theme park every day, a quick peek under the roof would reveal a manic scene. You would see associates, machinery, vehicles, robots, and packages flying about at break-neck speeds and accessing a breathtaking number of shelves and bins that store products. In reality, however, this activity is all highly organized and orchestrated by software, with each movement carefully planned and optimized. However, there are times when mistakes occur: products may disappear, reappear in strange places, become damaged, or worse. When that happens, how does a fulfillment center operating at that size, speed, and scale recover gracefully and with minimal cost? How do we ensure that we meet our commitments to our customers and merchants? How do we find a needle in a haystack when we’re constantly shuffling the haystack around? And how do we do it at extreme scale in an environment of constant growth?<br/>
<br/>
That’s where we come in, the AFT Inventory Entropy Management team. Our goal is to prevent entropy in a system in which there are billions of transactions driven by human and robotic input across hundreds of millions of items every year. We must ensure that the virtual and physical state of the world is aligned inside hundreds of Amazon’s fulfillment centers globally. When our job is done well mistakes are corrected quickly, and products are always ready to sell and ship.<br/>
<br/>
We operate at a nexus of machine learning, computer vision, robotics, and healthy measure of hard-earned expertise in operations to build automated, algorithmic approaches to solving these problems at minimal cost. We create cutting edge software, building automated processes and workflows in the most complex operational problem space in the business world. So what should you expect from this role?<br/>
<br/>
Major responsibilities: As a Data Scientist you will be working in one of the world's largest and most complex data analytics environments. You should have deep expertise in analyzing huge data sets from multiple domains. You should be expert at designing and implementing solutions that use a range of data science methodologies to automate data analysis or to solve complex business problems. You will design metrics for complex systems. You will deep dive ML training data and feature sets to drive improvements. You will partner with Research and Applied Scientists, SDEs, Technical Program Managers, Product Managers, and business leaders to identify solutions to large problems in Amazon Operations.<br/>
<br/>
Your analysis and solution recommendations will drive system optimizations with global impact. You will develop metrics to quantify the benefits of a solution and influence project resources. You will audit metric data and use it to measure system impact and performance.<br/>
<br/>
You will harness massive and diverse data sets to mine actionable insights for senior leaders. You will automate data feeds, validate the data input and analyze trends that lead to cost saving initiatives. In this role, you will own solving problems through deep data review, statistical analyses, and creation of analytic tools usable by others on the team. Your work products will guide our reporting, benchmarking, program optimization, financial planning, and execution strategy.<br/>
<br/>
The ideal candidate is a motivated self-starter who can thrive in a fast paced environment. They will enjoy working in a multidisciplinary team of engineers, scientists and business leaders. They will seek to understand processes behind data so their recommendations are grounded.

<ul><li>Graduate degree in a quantitative field</li><li>1+ years of experience in using a modern programming language (e.g. Java/C) to process data for modelling</li><li>Experience processing, filtering, and presenting large quantities (Millions of rows) of data</li><li>Experience working on large scale data transformation using AWS technologies, such as S3 and Redshift</li><li>Experience with advanced statistical methods (e.g., fixed effects, predictive modeling, cluster analysis, time series modeling)</li><li>Experience deriving business insights from the I/O of machine learning systems</li></ul><br/>
Amazon is an Equal Opportunity Employer – Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation / Age.</body>
</html>